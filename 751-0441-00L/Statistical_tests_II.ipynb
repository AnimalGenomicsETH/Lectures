{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190b7ae1-81b2-4f4c-aa56-15f3783a50f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## EXAMPLE 1\n",
    "\n",
    "# Consider some crop yield data from Frossard 2019, in particular the number of ears of wheat and the number of ears with grains\n",
    "crop_data <- read.table('Frossard_2019.csv',header=TRUE,sep=\",\")\n",
    "plot(crop_data$nr.ears.m2,crop_data$DW.ears_with_grains.g.m2, type = \"p\",col=\"darkgreen\",cex=3,lwd=4)\n",
    "\n",
    "# Let's calculate the correlation coefficient and p-value.\n",
    "# By default, it is the Pearson method.\n",
    "\n",
    "result <- cor.test(crop_data$nr.ears.m2,crop_data$DW.ears_with_grains.g.m2)\n",
    "result\n",
    "\n",
    "# print out the results in a nicer way.\n",
    "cat(\"\\nCorrelation\\n-------\\nr =\",result$estimate,\"\\nr2 =\",result$estimate**2,\"\\np =\",result$p.value,\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f442062-399e-44b6-b0d4-4cf9c0c35a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look now at the average annual temperature.\n",
    "# The years have been relabelled for simplicitly to start from 1.\n",
    "Temperatures <- c(51.5,52.0,52.5,52.7,48.6,52.3,49.6,50.8,51.0,52.8,52.0,52.6,53.0,52.9,51.4,50.8,51.2,50.3,51.0,50.4,51.6,50.6,49.7,51.0,53.9,53.5,52.1,50.6,51.8,51.7,51.2,52.4,50.1,53.6,50.3,54.7,53.9,54.3,53.4,52.9,53.3,53.7,53.8,52.0,55.0,52.1,53.4,53.8,53.8,51.9,52.1,52.7,51.8,56.6,53.3,55.6,56.3,56.2,56.1,56.2,53.6,55.7,56.3)\n",
    "Years <- c(1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63)\n",
    "plot(Years, Temperatures, type = \"p\",col=\"darkred\",cex=3,lwd=4)\n",
    "result <- cor.test(Years,Temperatures)\n",
    "cat(\"\\nCorrelation of annual temperatures\\nr =\",result$estimate,\"\\nr2 =\",result$estimate**2,\"\\np =\",result$p.value,\"\\n\")\n",
    "\n",
    "# Let's also look the Spearman and Kendall correlations.\n",
    "# We have \"ties\" in our data, where the temperatures are the same across two years.\n",
    "# We use an approximation to handle these ties rather than the exact method.\n",
    "\n",
    "result <- cor.test(Years,Temperatures,method='spearman',exact=F)\n",
    "cat(\"\\nCorrelation of annual temperatures (Spearman)\\nr =\",result$estimate,\"\\nr2 =\",result$estimate**2,\"\\np =\",result$p.value,\"\\n\")\n",
    "result <- cor.test(Years,Temperatures,method='kendall',exact=F)\n",
    "cat(\"\\nCorrelation of annual temperatures (Kendall)\\nr =\",result$estimate,\"\\nr2 =\",result$estimate**2,\"\\np =\",result$p.value,\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19321afe-4028-4925-a254-a88132d704bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## EXAMPLE 2\n",
    "\n",
    "# Consider 3 random variables that are normally distributed (with identical parameters).\n",
    "\n",
    "X <- rnorm(200,50,10)\n",
    "Y <- rnorm(200,50,10)\n",
    "Z <- rnorm(200,50,10)\n",
    "\n",
    "# Make a colour palette (\"viridis\"-like) that goes from blue->yellow.\n",
    "# Roughly bin the Z values so we can colour each scatter point by the Z value.\n",
    "# Let's calculate the correlation as well.\n",
    "\n",
    "YlOrBrRdBu <- c(\"#FDE725\", \"#21908C\", \"#3B528B\", \"#440154\")\n",
    "col <- colorRampPalette(YlOrBrRdBu)(50)\n",
    "cols = col[cut(Z,50)]\n",
    "plot(X, Y, col=cols,type = \"p\",cex=3,lwd=2)\n",
    "result <- cor.test(X,Y)\n",
    "cat(\"Correlation of X and Y\\nr =\",result$estimate,\"\\nr2 =\",result$estimate**2,\"\\np =\",result$p.value,\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e64337b-fb84-4b0c-a2eb-8cbb943c3f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's divide X & Y by Z.\n",
    "# This may be some normalisation procedure or similar approach.\n",
    "# We are using the same colours as determined in the previous panel.\n",
    "plot(X/Z, Y/Z, col=cols,type = \"p\",cex=3,lwd=2)\n",
    "result <- cor.test(X/Z,Y/Z)\n",
    "cat(\"Correlation of X and Y\\nr =\",result$estimate,\"\\nr2 =\",result$estimate**2,\"\\np =\",result$p.value,\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad31c41-f3e1-47bc-b015-0836edf28ad1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Install the corrplot package if necessary.\n",
    "\n",
    "install.packages(\"corrplot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68431158-c4d2-4e6c-9a43-82abc826e12e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Example 3\n",
    "\n",
    "# Load the corrplot package.\n",
    "\n",
    "library(corrplot)\n",
    "\n",
    "# Make a matrix with random expoential values, calculate the (pairwise) correlation matrix.\n",
    "\n",
    "A <- matrix(rexp(100,5),nrow=10)\n",
    "\n",
    "colnames(A) <- c(\"Alpha\",\"Bravo\",\"Charlie\",\"Delta\",\"Echo\",\"Foxtrot\",\"Golf\",\"Hotel\",\"India\",\"Juliett\")\n",
    "\n",
    "correlations <- cor(A,method=\"pearson\")\n",
    "\n",
    "# Also calculate the p-values for the correlations.\n",
    "p = cor.mtest(A)$p\n",
    "\n",
    "# Plot the correlation matrix, indicate which correlations are not significant.\n",
    "\n",
    "corrplot(correlations,type = \"upper\",p.mat=p,sig.level=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8fb7838-0eeb-46c4-a1fc-f9a46efd9333",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Further investigations\n",
    "\n",
    "## EXAMPLE 1\n",
    "# What will sorting the data (like ears <- sort(crop_data$nr.ears.m2)) first do to the correlation coefficients and significance?\n",
    "#\n",
    "# How does the correlation test relate to the linear regression results using the same variables?\n",
    "\n",
    "\n",
    "# What happens if you change year values slightly, how much do the correlations change?\n",
    "# Tip: You can add normally distributed random noise (mean=0 and sd=0.05) to Years as Years+rnorm(length(Years),0,.05)\n",
    "#\n",
    "# What happens to the correlations if you change one value to be a huge outlier?\n",
    "\n",
    "## EXAMPLE 2\n",
    "# What happens if you alter the standard deviation for X/Y/Z?\n",
    "#\n",
    "# Does it match the equation expectations from the slides?\n",
    "#\n",
    "# What could we do to make the results match expectations better?\n",
    "\n",
    "## EXAMPLE 3\n",
    "# Verify that the correlation matrix values match calculating the correlations between each column.\n",
    "# Hint: can access each column like A[,\"Alpha\"] or A[,\"Golf\"], and each element of the correlation matrix like correlations[\"Alpha\",\"Golf\"].\n",
    "#\n",
    "# If we change the distribution from exponential to normal, how many correlations are \"falsely\" significant?\n",
    "# What is the connection to multiple hypothesis correction (hint: there are approximately N^2 elements in the correlation matrix).\n",
    "#\n",
    "# If we change the correlation to spearman (from pearson), would we expect to see more significant correlations with the exponential distribution?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de697b9-7733-4676-9761-e419afd7ccfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "## EXAMPLE 1\n",
    "# What will sorting the data (like ears <- sort(crop_data$nr.ears.m2)) first do to the correlation coefficients and significance?\n",
    "\n",
    "# Sorting the data independently removes the relationship between the two variables, and so destroys the original correlation.\n",
    "\n",
    "ears <- sort(crop_data$nr.ears.m2)\n",
    "weight <- sort(crop_data$DW.ears_with_grains.g.m2)\n",
    "plot(ears, weight, type = \"p\",col=\"darkgreen\",cex=3,lwd=4)\n",
    "result <- cor.test(ears,weight)\n",
    "cat(\"Correlation of sports scores\\nr =\",result$estimate,\"\\nr2 =\",result$estimate**2,\"\\np =\",result$p.value,\"\\n\")\n",
    "\n",
    "# The plot now looks very correlated, as both variables were sorted separately, and indeed there is a strong and significant correlation.\n",
    "# Preprocessing data without careful thought can introduce or remove many important correlations, so be careful!\n",
    "# Instead, if we sort row by row, preserving the relationship, the plot looks the same as before.\n",
    "\n",
    "sorted_crop <- crop_data[order(crop_data$nr.ears.m2),]\n",
    "plot(sorted_crop$nr.ears.m2, sorted_crop$DW.ears_with_grains.g.m2, type = \"p\",col=\"darkgreen\",cex=3,lwd=4)\n",
    "\n",
    "# How does the correlation test relate to the linear regression results using the same variables?\n",
    "\n",
    "# Plot the data again, but now add the linear regression (remember it is y ~ x).\n",
    "plot(crop_data$nr.ears.m2,crop_data$DW.ears_with_grains.g.m2, type = \"p\",col=\"darkgreen\",cex=3,lwd=4)\n",
    "model <- lm(crop_data$DW.ears_with_grains.g.m2 ~ crop_data$nr.ears.m2)\n",
    "abline(model, col=\"red2\")\n",
    "summary(model)\n",
    "\n",
    "## Note the similarities in Multiple R-squared and p-value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2c11e2-c2ee-4ad0-a272-be786f6422e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## EXAMPLE 2\n",
    "# What happens if you change year values slightly, how much do the correlations change?\n",
    "# Tip: You can add normally distributed random noise (mean=0 and sd=0.05) to Years as Years+rnorm(length(Years),0,.05)\n",
    "\n",
    "\n",
    "Temperatures <- c(51.5,52.0,52.5,52.7,48.6,52.3,49.6,50.8,51.0,52.8,52.0,52.6,53.0,52.9,51.4,50.8,51.2,50.3,51.0,50.4,51.6,50.6,49.7,51.0,53.9,53.5,52.1,50.6,51.8,51.7,51.2,52.4,50.1,53.6,50.3,54.7,53.9,54.3,53.4,52.9,53.3,53.7,53.8,52.0,55.0,52.1,53.4,53.8,53.8,51.9,52.1,52.7,51.8,56.6,53.3,55.6,56.3,56.2,56.1,56.2,53.6,55.7,56.3)\n",
    "Years <- c(1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63)\n",
    "Years <- Years+rnorm(length(Years),0,2)\n",
    "plot(Years, Temperatures, type = \"p\",col=\"darkred\",cex=3,lwd=4)\n",
    "result <- cor.test(Years,Temperatures,method=\"pearson\",exact=F)\n",
    "cat(\"\\nCorrelation of annual temperatures\\nr =\",result$estimate,\"\\nr2 =\",result$estimate**2,\"\\np =\",result$p.value,\"\\n\")\n",
    "\n",
    "# There is a slight but insignificant change to the correlation and p value when using pearson R.\n",
    "# Since the years don't change enough to swap ranks, the spearman R is totally unchanged.\n",
    "# Increasing the variance to say 2 will affect both correlations.\n",
    "\n",
    "\n",
    "# What happens to the correlations if you change one value to be a huge outlier?\n",
    "\n",
    "# Pearson correlation can be totally changed (depending on how big the outlier is), but there will be almost no effect to spearman, as the coordinate doesn't matter, only the ranks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc11166b-9530-4bf4-b946-67930a58e2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## EXAMPLE 2\n",
    "# What happens if you alter the standard deviation for X/Y/Z?\n",
    "\n",
    "# If the standard deviation is huge the result is less significant, while a lower deviation is more reliably significant.\n",
    "# Huge outliers with high deviation can skew the data much more, so this is expected.\n",
    "\n",
    "# Does it match the equation expectations from the slides?\n",
    "\n",
    "X <- rnorm(200,50,10)\n",
    "Y <- rnorm(200,50,10)\n",
    "Z <- rnorm(200,50,10)\n",
    "result <- cor.test(X/Z,Y/Z)\n",
    "cat(\"Correlation of X and Y\\nr =\",result$estimate,\"\\nr2 =\",result$estimate**2,\"\\np =\",result$p.value,\"\\n\")\n",
    "\n",
    "X <- rnorm(200,50,5)\n",
    "Y <- rnorm(200,50,5)\n",
    "Z <- rnorm(200,50,20)\n",
    "result <- cor.test(X/Z,Y/Z)\n",
    "cat(\"Correlation of X and Y\\nr =\",result$estimate,\"\\nr2 =\",result$estimate**2,\"\\np =\",result$p.value,\"\\n\")\n",
    "\n",
    "# Yes, we can calculate this.\n",
    "# In the first case, the equation predicts r=0.5, and in the second it is about 0.941\n",
    "\n",
    "\n",
    "# What could we do to make the results match expectations better?\n",
    "\n",
    "X <- rnorm(200,10000,5)\n",
    "Y <- rnorm(200,10000,5)\n",
    "Z <- rnorm(200,10000,20)\n",
    "result <- cor.test(X/Z,Y/Z)\n",
    "cat(\"Correlation of X and Y\\nr =\",result$estimate,\"\\nr2 =\",result$estimate**2,\"\\np =\",result$p.value,\"\\n\")\n",
    "\n",
    "# The equation shown in the lectures is a slight approximation, as there is also a dependence on the mean in the full expression.\n",
    "# If we increase the mean, we can get r values much closer to 0.941."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a103e0-78f9-40c3-bf28-2f2389d2082a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## EXAMPLE 3\n",
    "# Verify that the correlation matrix values match calculating the correlations between each column.\n",
    "# Hint: can access each column like A[,\"Alpha\"] or A[,\"Golf\"], and each element of the correlation matrix like correlations[\"Alpha\",\"Golf\"].\n",
    "#\n",
    "cat(\"Direct test\\nr = \",cor.test(A[,\"Alpha\"],A[,\"Golf\"])$estimate,\"\\nMatrix correlation\\nr =\",correlations[\"Alpha\",\"Golf\"])\n",
    "\n",
    "# Yes they are the same.\n",
    "\n",
    "\n",
    "# If we change the distribution from exponential to normal, how many correlations are \"falsely\" significant?\n",
    "# What is the connection to multiple hypothesis correction (hint: there are approximately N^2 elements in the correlation matrix).\n",
    "\n",
    "A <- matrix(rexp(100),nrow=10)\n",
    "colnames(A) <- c(\"Alpha\",\"Bravo\",\"Charlie\",\"Delta\",\"Echo\",\"Foxtrot\",\"Golf\",\"Hotel\",\"India\",\"Juliett\")\n",
    "correlations <- cor(A,method=\"pearson\")\n",
    "p = cor.mtest(A)$p\n",
    "corrplot(correlations,type = \"upper\",p.mat=p,sig.level=0.05)\n",
    "\n",
    "# This is similar to what I showed in the lecture.\n",
    "# There are about (N**2)/2 tests, so out of the ~50 tests we might expect 2-3 to be signficant with p=0.05 by chance.\n",
    "# None would be significant if we did a correction.\n",
    "\n",
    "\n",
    "# If we change the correlation to spearman (from pearson), would we expect to see more significant correlations with the exponential distribution?\n",
    "\n",
    "# An exponential distribution generally has more extreme values (outliers) than a normal distribution, which could either lead to a larger or smaller correlation.\n",
    "# Since spearman is more robust to outliers (and we don't expect any signficance from a random set of values), we would expect it to have fewer significant correlations compared to pearson."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629de7af-0d7d-419e-8f2c-77e12f5cb9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "library(datasauRus)\n",
    "dino <- datasaurus_dozen[datasaurus_dozen$dataset == 'dino',]\n",
    "cor.test(dino$x,dino$y)\n",
    "slant_down <- datasaurus_dozen[datasaurus_dozen$dataset == 'slant_down',]\n",
    "cor.test(slant_down$x,slant_down$y)\n",
    "slant_up <- datasaurus_dozen[datasaurus_dozen$dataset == 'slant_up',]\n",
    "cor.test(slant_up$x,slant_up$y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.2.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
