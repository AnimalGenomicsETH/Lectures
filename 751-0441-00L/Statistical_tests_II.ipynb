{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa4b281c-a2fe-42f4-b2a8-f9f1943492b2",
   "metadata": {},
   "source": [
    "# Statistical Tests II\n",
    "---\n",
    "\n",
    "Solutions are provided below.  \n",
    "Each example contains easier parts at the start, plus more challenging extensions.  \n",
    "The extensions are useful to understand the concepts more generally, and are likely close to the difficulty of the final parts of an exam question.\n",
    "\n",
    "---\n",
    "\n",
    "#### Example 1\n",
    "\n",
    "Consider flipping a coin.\n",
    "There are two outcomes (heads or tails), and so this is called a \"Bernoulli trial\" (or binomial trial), and we can calculate the likehood of getting N number of heads with a binomial distribution.  \n",
    "What happens if a large group of people all flip coins?\n",
    "There are likely to be a few \"lucky\" people who end up with all heads or all tails, which is a form of multiple hypothesis testing.\n",
    " - Use random binomial variates to simulate flipping a coin 5 times, what distribution of heads or tails do you get?\n",
    " - Create a 1000x10 matrix (simulating 1000 people flipping a coin 10 times) and calculate the number of heads each person flips. What type of distribution does this look like and why?\n",
    " - Apply different MHT correction procedures and see how the number of remaining significant results remain. How would different correction procedures change your interpretation of the results?\n",
    "\n",
    "**Extension**\n",
    " - Does increasing/decreasing the number of people flipping coins or the number of coins each person flips make it more or less likely to get significant hits even after p value correction?\n",
    " - What sort of conditions would lead to one method being too conservative/lenient. Is it meaningful if you have a significant hit after one correction\n",
    "but not another?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c150dcb-9356-4450-9e70-9db4616ac1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's flip the coin 5 times, using the binomial distribution with a probability of 0.5.\n",
    "# Assume landing on heads is \"1\" and landing on tails is \"0\".\n",
    "Flips <- rbinom(5,1,.5)\n",
    "cat(\"Flips:\",Flips,\"\\nNumber of heads:\",sum(Flips),\"\\n\\n\")\n",
    "\n",
    "\n",
    "# Now let's simulate this for many people.\n",
    "# Flip 10,000 coins, and split into 1,000 people (so same as each flipping 10 times).\n",
    "Flips <- matrix(rbinom(10000,1,.5),nrow = 1000)\n",
    "\n",
    "# Sum over each row, so counting how many heads each person flipped.\n",
    "# Print the mean number of heads each person flipped, and a histogram.\n",
    "Sums <- rowSums(Flips)\n",
    "MeanHeads <- mean(Sums)\n",
    "cat(\"Mean number of heads flipped:\",MeanHeads,\"\\n\")\n",
    "hist(Sums,breaks = seq(-1,11,length.out = 12))\n",
    "\n",
    "# How does it look per person?\n",
    "# Would someone say the coin if unfair if they rolled 2 heads? 9 heads?\n",
    "cat(\"Rolling 2 heads: p =\",binom.test(2,10,.5)$p.value,\"\\nRolling 9 heads: p =\",binom.test(9,10,.5)$p.value,\"\\n\")\n",
    "\n",
    "# We have to correct for the number of people \"testing\" the coin, in this case 1000 people.\n",
    "# So the critical p-value isn't 0.05 anymore, but 0.05/1000 = 5e-5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc09cc5d-1a8b-464f-8055-f83977a37ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's push it a bit further, consider N flips and B people (so N/B flips per person)\n",
    "\n",
    "N = 10000\n",
    "B = 500\n",
    "cat(\"Number of flips per person: \",N/B,\"\\n\")\n",
    "\n",
    "# Change the seed used to generate random numbers, so we can *reproducibly* generate random datasets.\n",
    "# It is a complicated topic, but don't fall into the trap that similar seeds produce similar results.\n",
    "# Try commenting one value out and swapping the other in and see what happens.\n",
    "\n",
    "set.seed(6)\n",
    "#set.seed(5)\n",
    "\n",
    "# Generate per-person p values for a binomial test.\n",
    "# `sapply` applies the function given in the second argument to each element of data in the first argument.\n",
    "# This gives us the raw p values that each person calculated for their set of N/B flips.\n",
    "\n",
    "RawP <- sapply(sort(rowSums(matrix(rbinom(N,1,.5),nrow = B))), function(x) binom.test(x, N/B, .5)$p.value)\n",
    "cat(\"Number of \\\"significant\\\" tests without correction:\",sum(RawP<0.05),\"\\n\")               \n",
    "\n",
    "# Now we can correct the p values using two different methods.\n",
    "# Note that this adjusts the p values upwards, which is essentially equal to but more obvious than adjusting the significance threshold downwards.\n",
    "\n",
    "BP <- p.adjust(RawP,\"bonferroni\")\n",
    "BHP <- p.adjust(RawP,\"BH\")\n",
    "cat(\"Number of \\\"significant\\\" tests with Bonferroni correction:\",sum(BP<0.05),\"\\n\")       \n",
    "cat(\"Number of \\\"significant\\\" tests with Benjamini-Hochberg correction:\",sum(BHP<0.05),\"\\n\")       \n",
    "               \n",
    "# Plot the raw p values on the x-axis, and the two methods of correction on the y-axis.\n",
    "# The significance threshold is still p < 0.05, marked by the line.\n",
    "\n",
    "plot(RawP,BP,col=rgb(0,0,1),ylim=c(0,1),xlab=\"Raw p\",ylab=\"Adjusted p\")\n",
    "par(new = TRUE)\n",
    "plot(RawP,BHP,col=rgb(1,0,0),ylim=c(0,1),xlab=\"\",ylab=\"\")\n",
    "abline(0.05,0)\n",
    "legend(\"right\",c(\"Bonferroni\",\"Benjamini-Hochberg\"),fill=c(rgb(0,0,1),rgb(1,0,0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3eff02b2-53a4-4ffd-b4c2-6bfa2e224025",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of flips per person:  10 \n",
      "Number of \"significant\" tests without correction: 17 \n",
      "Number of \"significant\" tests with Bonferroni correction: 0 \n",
      "Number of flips per person:  2000 \n",
      "Number of \"significant\" tests without correction: 0 \n",
      "Number of \"significant\" tests with Bonferroni correction: 0 \n"
     ]
    }
   ],
   "source": [
    "## Example 1 extension\n",
    "\n",
    "# Does increasing/decreasing N or B make it more or less likely to get significant hits even after p value correction?\n",
    "\n",
    "# Repeat with a very distinct set of values\n",
    "N = 10000\n",
    "B = 1000\n",
    "cat(\"Number of flips per person: \",N/B,\"\\n\")\n",
    "RawP <- sapply(sort(rowSums(matrix(rbinom(N,1,.5),nrow = B))), function(x) binom.test(x, N/B, .5)$p.value)\n",
    "BP <- p.adjust(RawP,\"bonferroni\")\n",
    "cat(\"Number of \\\"significant\\\" tests without correction:\",sum(RawP<0.05),\"\\nNumber of \\\"significant\\\" tests with Bonferroni correction:\",sum(BP<0.05),\"\\n\")               \n",
    "\n",
    "N = 10000\n",
    "B = 10\n",
    "cat(\"Number of flips per person: \",N/B,\"\\n\")\n",
    "RawP <- sapply(sort(rowSums(matrix(rbinom(N,1,.5),nrow = B))), function(x) binom.test(x, N/B, .5)$p.value)\n",
    "BP <- p.adjust(RawP,\"bonferroni\")\n",
    "cat(\"Number of \\\"significant\\\" tests without correction:\",sum(RawP<0.05),\"\\nNumber of \\\"significant\\\" tests with Bonferroni correction:\",sum(BP<0.05),\"\\n\")               \n",
    "\n",
    "\n",
    "# The corrections are very robust, and so in general will never report any significant hits.\n",
    "# However, increasing N/B (so more flips per person) can result in a person getting a very signficant outlier, which may be significant after correction.\n",
    "# Similarly, decreasing N/B (so more people flipping less coins) means the correction factor is higher, so even less likely for a signficant result after correction.\n",
    "\n",
    " \n",
    "               \n",
    "# What sort of conditions would lead to one method being too conservative/lenient. Is it meaningful if you have a significant hit after one correction\n",
    "# but not another?\n",
    "\n",
    "# If your probabilities are very unevenly distibuted (so a few highly signficiant values and a few non-signifant values), then the Bonferroni correction will be much stricter than B-H.\n",
    "# They are both valid choices, so there is not any meaningful conclusion if p-values are significant after one correction but not the other. \n",
    "# However, it is important not to change your method because you didn't like the outcome (p-value hacking!)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f23df8-3f02-4243-9c3c-8a20761c3f1b",
   "metadata": {},
   "source": [
    "---\n",
    "#### Example 2\n",
    "\n",
    "We will examine the data in Frossard_2019 again, looking at statistical results across different variables.\n",
    " - Examine the variance of the *DW.grain.kg.ha* and *SPAD.afternoon* variables, are they similar? Are they statistically significantly similar?\n",
    " - Comparing the Bockris and Titlis varieties, is there a statistically significant difference in variances?\n",
    " - Test if the amount of fertilizer used has an impact on the *harvest.index*.\n",
    " - What happens if we swap the order of variables around. This didn't matter for correlation analyses, will it here?\n",
    "\n",
    "**Extension**\n",
    " - Test if *DW.grain.kg.ha* and *SPAD.afternoon* are normally distributed variables.\n",
    " - Test for any significant differences between the above variables.\n",
    " - Linear regression (covered soon) will also produce an F-statistic, can we calculate the sample size needed for this to be significant?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563210b1-0284-4975-86e7-b80697c8d47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in data used in the previous lecture\n",
    "crop_data <- read.table('Frossard_2019.csv',header=TRUE,sep=\",\")\n",
    "head(crop_data)\n",
    "\n",
    "# Let's look at the variance for two of the variables.\n",
    "var(crop_data$DW.grain.kg.ha)\n",
    "var(crop_data$SPAD.afternoon)\n",
    "\n",
    "# We can use an F-test to see if they have equal variances.\n",
    "var.test(crop_data$DW.grain.kg.ha,crop_data$SPAD.afternoon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5652af5-22ef-4021-8395-23c7180980c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slightly more advanced, but we can compare the variances between two groups (the two varieties) for specific variables.\n",
    "# Here, let's look at the \"DW.grain.kg.ha\" quantity, and see if there is a difference in variance for the two varieties.\n",
    "# We can do that manually by separating out the data and testing (using the more robust Bartlett test), or a more advanced notation using \"~\".\n",
    "bockris <- crop_data[crop_data$variety == \"Bockris\",]\n",
    "titlis <- crop_data[crop_data$variety == \"Titlis\",]\n",
    "bartlett.test(list(bockris$DW.grain.kg.ha,titlis$DW.grain.kg.ha))\n",
    "\n",
    "# And this should be equal (but easier to write!)\n",
    "bartlett.test(DW.grain.kg.ha ~ variety, data = crop_data)\n",
    "var.test(DW.grain.kg.ha ~ variety, data = crop_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c94695-fc4c-44d0-a76f-2611bb11605c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kruskal-Wallis is the appropriate test to use\n",
    "kruskal.test(harvest.index ~ fertilizer, data = crop_data)\n",
    "\n",
    "# The order-response variables **matters** a lot.\n",
    "# If you swap the order, it is no longer the same analysis (as it was in correlation and many other statistical tests).\n",
    "kruskal.test(fertilizer ~ harvest.index, data = crop_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17fe5bf7-4d8a-453f-834c-028fd39eca5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Example 2 extension\n",
    "\n",
    "# Consider another set of variables, are they normal?\n",
    "shapiro.test(crop_data$DW.grain.kg.ha)\n",
    "shapiro.test(crop_data$SPAD.afternoon)\n",
    "\n",
    "# The data does approximately satisfy the requirements for an F-test, so the nonparametric version is less powerful than the parametric version covered soon (ANOVA).\n",
    "kruskal.test(DW.grain.kg.ha ~ SPAD.afternoon, data = crop_data)\n",
    "\n",
    "# This is jumping ahead to a future lecture, but this will calculate the linear regression and plot the fit.\n",
    "# This uses F-tests as we covered in the first Statistical Tests lecture, but here is not a large enough sample size to be significant.\n",
    "regression <- lm(DW.grain.kg.ha ~ SPAD.afternoon, data=crop_data)\n",
    "summary(regression)\n",
    "plot(DW.grain.kg.ha ~ SPAD.afternoon, data = crop_data)\n",
    "abline(regression,col=\"red\",lw=4)\n",
    "\n",
    "# Given the F statistic calculated from the regression,  how many samples would we need (assuming they follow the same pattern as the existing data) to be significant?\n",
    "# We can calculate this based on the F-distribution and look for the critical value we need (p=0.05)\n",
    "my.F <- summary(regression)$fstatistic[1]\n",
    "\n",
    "# Creates a range of sample sizes we want to calculate the significance for.\n",
    "my.n <- 18:1000\n",
    "\n",
    "# Calculate significance for each n and plot.\n",
    "my.p <- pf(my.F, 1, my.n-2, lower.tail=F)\n",
    "plot(my.p, my.n, type=\"l\")\n",
    "abline(v=0.05, col=\"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa78286-03a8-4ff0-b5f9-a27712c8fd5e",
   "metadata": {},
   "source": [
    "---\n",
    "#### Example 3\n",
    "\n",
    "We can also examine the PlantGrowth dataset based on observations for growth using different treatments.\n",
    " - Make a boxplot of the *weight* against each of the *group* variables.\n",
    " - Test if there are any significant differences present.\n",
    " - Use a nonparametric posthoc test to find which groups result in different growth rates.\n",
    "\n",
    "**Extension**\n",
    " - The default pairwise test correction uses the \"Holm\" procedure. How do other options (\"none\",\"hochberg\", \"hommel\", \"bonferroni\", \"BH\", \"BY\") compare?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c462563a-64a6-4ddf-b379-0ce30eb93da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a default dataset for the weight of plants after 3 different types of treatments.\n",
    "# Plot the weights as boxplots to visualise potential group differences.\n",
    "boxplot(weight ~ group, data = PlantGrowth, frame = FALSE,\n",
    "        col = c(\"#999999\", \"#E69F00\", \"#56B4E9\"))\n",
    "\n",
    "# We want to test if there is any significant differences between the three groups.\n",
    "# We will use the Kruskal-Wallis test.\n",
    "kruskal.test(PlantGrowth$weight, PlantGrowth$group)\n",
    "\n",
    "\n",
    "# However, this just shows that there is a significant difference, but it is not clear between which groups.\n",
    "# We can do pairwise tests (e.g. \"ctrl\" and \"trt1\", \"ctrl\" and \"trt2\", etc.) to see which are significant.\n",
    "# Be careful, as we are now testing multiple hypotheses and so should correct accordingly.\n",
    "pairwise.wilcox.test(PlantGrowth$weight, PlantGrowth$group,   p.adjust.method = \"holm\",exact=F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84ac96a-814c-44ae-83d1-a9862b72a512",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Example 3 extension\n",
    "\n",
    "pairwise.wilcox.test(PlantGrowth$weight, PlantGrowth$group,   p.adjust.method = \"none\",exact=F)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ceeaa4f-f29b-4839-a6d2-d53f3a8fafcc",
   "metadata": {},
   "source": [
    "---\n",
    "#### Example 4\n",
    "\n",
    "We can also examine the iris dataset based on observations for flower growth.\n",
    " - Create a boxplot using the builtin \"iris\" dataset, plotting *Sepal.width* against *Species*.\n",
    " - Test if any species have a statistically different sepal width.\n",
    "   - Use a posthoc test to find out which species may be significantly different.\n",
    " - Use the `matrixTests` package to test for differences across multiple variables at once, and confirm it matches the results from before.\n",
    "\n",
    "**Extension**\n",
    " - Perform posthoc tests for the multiple Kruskal-Wallis tests conducted when using the `matrixTests` package in the previous part.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c277829-8144-43a8-abc1-44db7dd15651",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also look at a different dataset.\n",
    "# Use the \"iris\" default dataset for flowers.\n",
    "head(iris)\n",
    "\n",
    "# Here we will plot the sepal width for the three different species.\n",
    "boxplot(Sepal.Width ~ Species, data = iris, frame = FALSE,\n",
    "        col = c(\"#999999\", \"#E69F00\", \"#56B4E9\"))\n",
    "\n",
    "# However, there are other variables, so we can try and plot this as an \"all-versus-all\" pair plot.\n",
    "# First we should convert the numeric data to a matrix, and also turn the species names into numeric values to make plotting easier.\n",
    "ma <- as.matrix(iris[, 1:4])\n",
    "speciesID <- as.numeric(iris$Species)\n",
    "pairs(ma, col = rainbow(3)[speciesID])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d906bf-1557-4f15-aade-af36b7091d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's test the significance of sepal length for the different species.\n",
    "kruskal.test(iris$Sepal.Width, iris$Species)\n",
    "\n",
    "# And again do a pairwise test to see which groups are significant.\n",
    "pairwise.wilcox.test(iris$Sepal.Width, iris$Species,   p.adjust.method = \"BH\",exact=F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3585245d-dae0-40f9-9b55-221f58dc1b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install and load a package called matrixTests we will use for simplicity.\n",
    "install.packages(\"matrixTests\")\n",
    "library(\"matrixTests\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e963234-906d-49b2-88f6-1329723a3109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can do a column-wise test for all the variables.\n",
    "col_kruskalwallis(ma, speciesID)\n",
    "\n",
    "# Compare to doing each test manually, and confirm identical results.\n",
    "# Note the p-values that are too small get reported as < 2.2e-16, because the computer loses accuracy for numbers smaller than this.\n",
    "# To get the exact number back, we will add $p.value immediately to get the full accuracy value.\n",
    "kruskal.test(iris$Sepal.Length, iris$Species)$p.value\n",
    "kruskal.test(iris$Sepal.Width, iris$Species)$p.value\n",
    "kruskal.test(iris$Petal.Length, iris$Species)$p.value\n",
    "kruskal.test(iris$Petal.Width, iris$Species)$p.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f957d0a4-93c6-4cbb-9136-78b2f6752e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Example 4 extension\n",
    "\n",
    "# There is no obvious way to do multiple multiple hypothesis testing, so we can do this manually for the four tested variables.\n",
    "pairwise.wilcox.test(iris$Sepal.Length, iris$Species,   p.adjust.method = \"BH\",exact=F)\n",
    "pairwise.wilcox.test(iris$Sepal.Width, iris$Species,   p.adjust.method = \"BH\",exact=F)\n",
    "pairwise.wilcox.test(iris$Petal.Length, iris$Species,   p.adjust.method = \"BH\",exact=F)\n",
    "pairwise.wilcox.test(iris$Petal.Width, iris$Species,   p.adjust.method = \"BH\",exact=F)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19b7762-ee33-4792-80de-63ba9539e8bb",
   "metadata": {},
   "source": [
    "---\n",
    "## Real world example\n",
    "\n",
    "This is a slightly more realistic case, where we are examining some [actual data](https://opendata.swiss/en/dataset/rinder-geburten-nach-kantonen).  \n",
    "The goal here is to manipulate the data into a useful shape, and then assess statistical significance.  \n",
    "These examples are harder than you would encounter in an exam and use more advanced data analysis techniques, but are useful to try.\n",
    "\n",
    "This data is the number of cattle born each month for each canton in Switzerland\n",
    " - Similar to the exercise in *Statistical Tests I*, aggregate the data over each month to make annual totals.\n",
    " - Subset out some cantons and look if the annual number of births is correlated between them.\n",
    " - Reshape the data to be \"long\" rather than \"wide\" (\"melting\" the different columns for each canton to become a variable in each row).\n",
    " - Create a boxplot for a subset of the cantons and then conduct a statistical test to check if any canton has a significant difference.\n",
    "   - Conduct posthoc tests to find which cantons are the significantly different ones (taking care to correct for MHT). \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c742a9a-3bdd-4e6c-8561-1e58a2fa10fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the semi-colon separated data, skipping the first line which is a comment.\n",
    "births <- read.csv('cattle-birthCanton.csv',sep=';',skip=1)\n",
    "\n",
    "# We want to sum over *all* columns by aggregating over year, so we can use the ~ syntax over \".\" (all coloumns). \n",
    "grouped_births <- aggregate(. ~ Year,data=births, FUN=sum)\n",
    "grouped_births\n",
    "\n",
    "\n",
    "\n",
    "# and we can test for correlations between the cantons, here are two examples.\n",
    "cor.test( grouped_births$AG, grouped_births$VD)\n",
    "cor.test( grouped_births$BE, grouped_births$VS)\n",
    "\n",
    "# We want to test if there is any significant differences between the three groups.\n",
    "# We will use the Kruskal-Wallis test.\n",
    "\n",
    "# We'll reshape the dataframe (\"melt\" it) so the cantons change from being columns to being row values\n",
    "melted_births <- reshape2::melt(grouped_births, id.vars = c(\"Year\", \"Month\"),variable.name = \"Canton\", value.name = \"Births\")\n",
    "\n",
    "# We'll look at a subset of four cantons and plot the number of births of the different years\n",
    "melted_births_subset1 <- melted_births[melted_births$Canton %in% c('AG','VD','BE','VS'),]\n",
    "plot(Births ~ Year, data = melted_births_subset1,col=factor(melted_births_subset1$Canton),frame = FALSE)\n",
    "\n",
    "# We'll take another subset of cantons \n",
    "melted_births_subset2 <- melted_births[melted_births$Canton %in% c('GR','TG','ZH','SZ','SO','UR','TI'),]\n",
    "\n",
    "# We need to convert the column type from \"fct\" (function) to \"str\" (string), which will remove all the cantons we don't care about above.\n",
    "# You should try redoing the boxplot after commenting out these two lines and seeing what changes.\n",
    "i <- sapply(melted_births_subset2, is.factor)\n",
    "melted_births_subset2[i] <- lapply(melted_births_subset2[i], as.character)\n",
    "\n",
    "\n",
    "boxplot(Births ~ Canton, data = melted_births_subset2, frame = FALSE)\n",
    "\n",
    "# We will use the Kruskal-Wallis test to test if there is any significant differences between the cantons.\n",
    "kruskal.test(Births ~ Canton, data = melted_births_subset2)\n",
    "\n",
    "# However, this just shows that there is *a* significant difference, but it is not clear between which groups.\n",
    "# We can do pairwise tests (e.g. SZ and ZH, SZ and SO, etc.) to see which are significant.\n",
    "# Be careful, as we are now testing multiple hypotheses and so we need to correct accordingly.\n",
    "pairwise.t.test(melted_births_subset2$Births, melted_births_subset2$Canton, p.adjust.method = \"bonf\",paired=TRUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c011a93-9779-4dd7-a20a-5087b7b9ddd3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.2.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
