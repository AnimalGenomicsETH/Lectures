{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39e58c9f-f4d1-4f79-96ed-0a6cb04b23ac",
   "metadata": {},
   "source": [
    "## EXAMPLE 1 -- simple statistical test\n",
    "\n",
    "Let's *test* if students choose seating in a non-random way. \\\n",
    "A null hypothesis is that students choose seats at random, so we would expect a 50/50 split between the left and the right of the classroom. \\\n",
    "However, let us consider 100 students, where 36 sit on the left and 64 sit on the right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8999cf1d-1b41-414f-a0b1-55f33338575e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat(\"Binomial test p =\",binom.test(64,100,.5)$p.value,\"\\n\\n\")\n",
    "\n",
    "# trivially this is the same as considering those who sat on the other side\n",
    "cat(\"Binomial test p =\",binom.test(36,100,.5)$p.value,\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb3a155-682b-4eee-9b55-99dae654e932",
   "metadata": {
    "tags": []
   },
   "source": [
    "Let's now create a 2x2 \"observation\" matrix by reshaping a 4x1 list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b38fba-9356-4882-a1c0-1b06c0083ef4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Seating <- matrix(c(36, 50, 64, 50),\n",
    "       nrow = 2,\n",
    "       dimnames = list(c(\"Observed\", \"Expectation\"),\n",
    "                       c(\"Left\", \"Right\")))\n",
    "\n",
    "# View the matrix to check it is right\n",
    "\n",
    "print(Seating)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec173ce-3a8f-4417-a4c4-9a70a3010e5f",
   "metadata": {
    "tags": []
   },
   "source": [
    "We'll now perform Fisher's exact test on the matrix. \\\n",
    "This is by default a two-sided test, checking if there is *a* difference. \\\n",
    "What if the right side is closer to the door, so we think people might prefer that side? \\\n",
    "We can also use a one-sided version to test if \"more people sit on the left than expected\" or \"less people sit on the left than expected\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47138f94-19ca-401c-a9ef-09fd7582b14d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Print out the test results.\n",
    "# Using `cat` allows us to print more complex statements with multiple parts (the initial text and then also the p value).\n",
    "# The `\\n` are special characters to add new lines and make the printing easier to read.\n",
    "\n",
    "result <- fisher.test(Seating)\n",
    "cat(\"\\nFisher's exact test (Two-sided)\\np =\",result$p,\"\\n\")\n",
    "\n",
    "result <- fisher.test(Seating, alternative=\"greater\")\n",
    "cat(\"\\nFisher's exact test (One-sided)\\np =\",result$p,\"\\n\")\n",
    "\n",
    "result <- fisher.test(Seating, alternative=\"less\")\n",
    "cat(\"\\nFisher's exact test (One-sided)\\np =\",result$p,\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63cc269a-34ab-4cda-9682-4a389feb1937",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at the \"marginals\" in more detail.\n",
    "# addMargins sums these values for a matrix.\n",
    "\n",
    "print(addmargins(Seating))\n",
    "\n",
    "# Consider a slightly different seating arrangement.\n",
    "\n",
    "Seating <- matrix(c(45, 50, 55, 50),\n",
    "       nrow = 2,\n",
    "       dimnames = list(c(\"Observed\", \"Expectation\"),\n",
    "                       c(\"Left\", \"Right\")))\n",
    "\n",
    "# Now look at the margins  compared to before.\n",
    "# The sum over the columns (on the right side) are still equal to 100.\n",
    "# This should be fixed, we have 100 students no matter what (unless the lecture is that bad and they leave halfway through).\n",
    "# However, the sum over the rows can change depending on where students can sit, and so this is NOT fixed.\n",
    "\n",
    "cat(\"\\n\")\n",
    "print(addmargins(Seating))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba3193c-b49a-45a7-8151-ccb2b964f784",
   "metadata": {},
   "outputs": [],
   "source": [
    "## EXAMPLE 2\n",
    "\n",
    "# Let's consider (randomly generated) dairy yield from two different cattle breeds.\n",
    "# 1000 normally distributed yield variantes, with a slightly different means but both with standard deviation of 2.\n",
    "\n",
    "holstein <- rnorm(1000,90,2)\n",
    "brown_swiss <- rnorm(1000,88,2)\n",
    "\n",
    "# Let's plot the distribution just to help visualise.\n",
    "# Plotting these as histograms with different colours in the same plot (add=T) and title (main=\"Exam results\").\n",
    "\n",
    "hist(holstein,col=rgb(0,0,1,1/4), xlim=c(80,100),main=\"Milk yield\",xlab=\"yield (L)\")\n",
    "hist(brown_swiss,col=rgb(1,0,0,1/4), xlim=c(80,100),add=T)\n",
    "\n",
    "# Manually add a legend to the plot for the two classes\n",
    "\n",
    "legend(\"topright\",c(\"Holstein\",\"Brown Swiss\"),fill=c(rgb(0,0,1,1/4),rgb(1,0,0,1/4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf6803d-54bb-435a-b865-4a0645651df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's test if two different cattle breeds have the same milk yield.\n",
    "# Our null hypothesis is that the two breeds have the same yield.\n",
    "# Can use the t-test, which assumes normally distributed data and equal variances.\n",
    "\n",
    "result <- t.test(holstein,brown_swiss,var.equal=T)\n",
    "cat(\"p =\",result$p.value,\"\\ndof =\",result$parameter,\"\\nt statistic =\",result$statistic,\"\\n\")\n",
    "\n",
    "# Given the degrees of freedom and the t statistic, we can also calculate the p-value from the theoretical Students t distribution.\n",
    "# Because we used a two-sided test, multiply the result by 2.\n",
    "\n",
    "cat(\"Distribution calculated p =\",2*pt(result$statistic,result$parameter, lower.tail=FALSE),\"\\n\\n\\n\")\n",
    "\n",
    "cor.test(sort(brown_swiss),sort(holstein))\n",
    "summary(lm(sort(brown_swiss) ~ sort(holstein)))\n",
    "\n",
    "summary(lm(sort(brown_swiss) ~ sort(holstein)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c555330-92b6-47d9-9ad3-c09bfc38c84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## EXAMPLE 4\n",
    "\n",
    "# Consider the crop harvest at many different locations over two different years\n",
    "\n",
    "year_2022 <- c(180,161,188,151,178,160,190,172,118,164,222,217,155,165,129,193,210,191,176,205,170,167,189)\n",
    "year_2023 <- c(133,211,168,137,144,172,143,174,139,156,170,162,212,170,171,161,177,162,151,186,132,158,97)\n",
    "\n",
    "# How do the distributions look like?\n",
    "# Wouldn't expect anything too obvious since the locations could all be quite different\n",
    "\n",
    "hist(year_2022,col=rgb(1,0,0,1/4),breaks = seq(50,250,length.out = 16),main=\"Crop yield\",xlab=\"yield (kg)\")\n",
    "hist(year_2023,col=rgb(0,0,1,1/4),breaks = seq(50,250,length.out = 16), add=T) \n",
    "legend(\"right\",c(\"2022\",\"2023\"),fill=c(rgb(0,0,1,1/4),rgb(1,0,0,1/4)))\n",
    "\n",
    "plot(year_2022,year_2023,col=rgb(0,0,1),xlab=\"Raw p\",ylab=\"Adjusted p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fff38f7-f721-492e-948c-98b8f63bc921",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's confirm it is appropriate to assume they are normal distributions\n",
    "\n",
    "cat(\"2022 p =\",shapiro.test(year_2022)$p,\"\\n\")\n",
    "cat(\"2023 p =\",shapiro.test(year_2023)$p,\"\\n\")\n",
    "\n",
    "# And let's look at their mean values\n",
    "\n",
    "cat(\"2022 mean =\",mean(year_2022),\"\\n\")\n",
    "cat(\"2023 mean =\",mean(year_2023),\"\\n\")\n",
    "\n",
    "# And finally let's test that there is a difference in these samples.\n",
    "# Since the distributions are not normal etc, we should use a non-parametric test.\n",
    "# Technically, the null hypothesis that the distributions are identical, and you would not expect to draw larger values from one population.\n",
    "\n",
    "cat(\"Mannâ€“Whitney U test p =\",wilcox.test(year_2022, year_2023, paired = FALSE,exact=F)$p.value,\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e191fa86-948e-4efa-9543-23e0dc0e8c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Further investigations\n",
    "\n",
    "## EXAMPLE 1\n",
    "# Does the sample size make much difference? Consider looking at the chi-square test (chisq).\n",
    "#\n",
    "# Can we generalise to more than 2 categeories (first row of seats, second row of seats, third row of seats, etc.)?\n",
    "\n",
    "## EXAMPLE 2\n",
    "# Does changing var.equal in EXAMPLE 2 to false change the results much?\n",
    "#\n",
    "# What if we change the variances in the milk yields from 2 to something different for each class?\n",
    "#\n",
    "# Can you find an example where a TRUE/FALSE value for var.equal would give a significant or not-significant result? What would that mean?\n",
    "\n",
    "## EXAMPLE 3\n",
    "# Does increasing/decreasing N or B make it more or less likely to get significant hits even after p value correction?\n",
    "#\n",
    "# What sort of conditions would lead to one method being too conservative/lenient. Is it meaningful if you have a significant hit after one correction\n",
    "# but not another?\n",
    "\n",
    "## EXAMPLE 4\n",
    "# Consider if the crop yields from 2022 and 2023 were measured at the same set of locations, so the first yield from 2022 and 2023 are from the same field.\n",
    "# The yields are now \"paired\" and can be compared more directly rather than just a list of yields.\n",
    "#\n",
    "# We can then use a paired wilcox test, but how does this affect the results? What is the interpretation?\n",
    "#\n",
    "# What if we ignored the fact the data is not normally distributed, and used something like a paired t-test? How does that look? How does that relate\n",
    "# to the power of the test?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63b7b12-842b-431a-b1c1-2e29a141775d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## EXAMPLE 1\n",
    "# Does the sample size make much difference? Consider looking at the chi-square test (chisq).\n",
    "\n",
    "Seating <- matrix(c(360, 500, 640, 500),\n",
    "       nrow = 2,\n",
    "       dimnames = list(c(\"Observed\", \"Expectation\"),\n",
    "                       c(\"Left\", \"Right\")))\n",
    "result <- fisher.test(Seating)\n",
    "cat(\"\\nFisher's exact test (Two-sided)\\np =\",result$p,\"\\n\")\n",
    "\n",
    "#Yes, larger sample size (but proportionally the same) is highly statistically significant. Smaller sample sizes are much harder to be significant.\n",
    "\n",
    "cat(\"\\nChi Square test (Two-sided)\\np =\",chisq.test(Seating)$p.value,\"\\n\")\n",
    "\n",
    "# The chi square test is very similar, but since it is non-parametric, it is less powerful than Fisher's exact test in this case. But it is also more general.\n",
    "\n",
    "\n",
    "\n",
    "# Can we generalise to more than 2 categeories (first row of seats, second row of seats, third row of seats, etc.)?\n",
    "\n",
    "# Make a larger matrix with a few extra value\n",
    "\n",
    "Seating <- matrix(c(10, 25, 40, 25,28,22, 30,20, 24,26, 15, 35),\n",
    "       nrow = 2,       \n",
    "       dimnames = list(c(\"Observed\", \"Expectation\"),\n",
    "                       c(\"Row 1\", \"Row 2\", \"Row 3\",\"Row 4\", \"Row 5\",\"Row 6\")))\n",
    "\n",
    "# chi square test works fine, but Fisher's exact test gives an error (as the exact test becomes too hard to calculate, it is mostly for 2x2 matrices).\n",
    "print(Seating)\n",
    "cat(\"\\nChi Square test (Two-sided)\\np =\",chisq.test(Seating)$p.value,\"\\n\")\n",
    "cat(\"\\nFisher's exact test (Two-sided)\\np =\",fisher.test(Seating)$p,\"\\n\")\n",
    "\n",
    "# can approximate the larger Fisher test using \"simulate.p.value=TRUE\"\n",
    "#cat(\"\\nFisher's exact test (Two-sided)\\np =\",fisher.test(Seating,simulate.p.value=TRUE)$p,\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14aa8657-18eb-412c-8cac-bf37c346bc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## EXAMPLE 2\n",
    "# Does changing var.equal in EXAMPLE 2 to false change the results much?\n",
    "#\n",
    " \n",
    "holstein <- rnorm(1000,90,2)\n",
    "brown_swiss <- rnorm(1000,88,2)\n",
    "\n",
    "result <- t.test(holstein,brown_swiss,var.equal=F)\n",
    "cat(\"p =\",result$p.value,\"\\ndof =\",result$parameter,\"\\nt statistic =\",result$statistic,\"\\n\")\n",
    "\n",
    "#There is a tiny change in degrees of freedom when variance is not equal (it is now \"Welch's t-test\"), but no change to t statistic and p value is still significant.\n",
    "\n",
    "\n",
    "# What if we change the variances in the milk yield from 2 to something different for each class?\n",
    "\n",
    "holstein <- rnorm(1000,90,3)\n",
    "brown_swiss <- rnorm(1000,88,4)\n",
    "\n",
    "result <- t.test(holstein,brown_swiss,var.equal=F)\n",
    "cat(\"p =\",result$p.value,\"\\ndof =\",result$parameter,\"\\nt statistic =\",result$statistic,\"\\n\")\n",
    "\n",
    "# Still significant, but there is a larger drop in degrees of freedom and t-statistic, as the distribitions of milk yields are more likely to overlap with larger variance.\n",
    "\n",
    "# Can you find an example where a TRUE/FALSE value for var.equal would give a significant or not-significant result? What would that mean?\n",
    "\n",
    "# There will be some parameters and random seed that will do this (similar to the case in Example 1).\n",
    "# If the variance truly is equal, then picking var.equal=F and getting a non-significant result means you used an \"under-powered\" test, and incorrectly will say it is non-significant (false negative error).\n",
    "# Alternatively, picking var.equal=T when they are not might mean your test is \"over-powered\" and you are incorrectly reporting it is as significant (false positive error)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6992e97a-11a1-4a58-9afa-768cbfc60cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "## EXAMPLE 3\n",
    "# Does increasing/decreasing N or B make it more or less likely to get significant hits even after p value correction?\n",
    "#\n",
    "# The corrections are very robust, and so in general will never report any significant hits.\n",
    "# However, increasing N/B (so more flips per person) can result in a person getting a very signficant outlier, which may be significant after correction.\n",
    "# Similarly, decreasing N/B (so more people flipping less coins) means the correction factor is higher, so even less likely for a signficant result after correction.\n",
    "\n",
    "\n",
    "# What sort of conditions would lead to one method being too conservative/lenient. Is it meaningful if you have a significant hit after one correction\n",
    "# but not another?\n",
    "\n",
    "# If your probabilities are very unevenly distibuted (so a few highly signficiant values and a few non-signifant values), then the Bonferroni correction will be much stricter than B-H.\n",
    "# They are both valid choices, so there is not any meaningful conclusion if p-values are significant after one correction but not the other. \n",
    "# However, it is important not to change your method because you didn't like the outcome (p-value hacking!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7414d2c-538c-4f77-8abc-af7e836b93e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## EXAMPLE 4\n",
    "# Consider if the crop yields from 2022 and 2023 were measured at the same set of locations, so the first yield from 2022 and 2023 are from the same field.\n",
    "# The yields are now \"paired\" and can be compared more directly rather than just a list of yields.\n",
    "#\n",
    "# We can then use a paired wilcox test, but how does this affect the results? What is the interpretation?\n",
    "#\n",
    "\n",
    "cat(\"Mannâ€“Whitney U test p =\",wilcox.test(year_2022, year_2023, paired = F,exact=F)$p.value,\"\\n\")\n",
    "cat(\"Mannâ€“Whitney U test p =\",wilcox.test(year_2022, year_2023, paired = T,exact=F)$p.value,\"\\n\")\n",
    "\n",
    "# In this case, the test is still significant, but a lot weaker and the effect size is also lower (see lecture 6).\n",
    "# Before we were considering if one year had higher yield than the the other in general, but now we can also say one year yielded more crops from the same locations than the other year (so is easier to support a claim of \"better\").\n",
    "\n",
    "\n",
    "# What if we ignored the fact the data is not normally distributed, and used something like a paired t-test? How does that look? How does that relate\n",
    "# to the power of the test?\n",
    "\n",
    "cat(\"Student's t test (unpaired) p =\",t.test(year_2022, year_2023, paired = F)$p.value,\"\\n\")\n",
    "cat(\"Student's t test (paired) p =\",t.test(year_2022, year_2023, paired = T)$p.value,\"\\n\")\n",
    "\n",
    "# Interestingly the p-value is higher for unpaired and lower for paired.\n",
    "# In general, since this test assumption is not appropriate (not normally distributed and too small sample size to approximate normality), it may be over/under-powered, depending on where the t-distribution is being tested."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8577f61e-4131-4306-bcbd-20c2e5984bb7",
   "metadata": {},
   "source": [
    "## Additional example\n",
    "\n",
    "This is a slightly more realistic case, where we are examining some actual data. \\\n",
    "The goal here is to manipulate the data into a useful shape, and then assess statistical significance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e00046-c74f-4567-9d70-7da790a747db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the data from the csv, which uses ';' as the separator rather than ','\n",
    "# the first row of the file is also some download information rather than data, so we skip the first row\n",
    "slaughter_weights <- read.csv('../../cattle-slaughterWeights.csv',sep=';',skip=1)\n",
    "print(head(slaughter_weights,n=20))\n",
    "\n",
    "# we now want to reshape the data to sum over the 12 months in a year for each TypeOfUse and Year\n",
    "grouped_weights <- aggregate(cbind(tot_number_animals=slaughter_weights$tot_number_animals), by=list(TypeOfUse=slaughter_weights$TypeOfUse,Year=slaughter_weights$Year), FUN=sum)\n",
    "\n",
    "# we can also do this more compactly with the '~' formula syntax, which produces the same output \n",
    "grouped_weights <- aggregate(tot_number_animals ~ TypeOfUse + Year,data=slaughter_weights, FUN=sum)\n",
    "\n",
    "# print out the new dataframe so we can see it\n",
    "print(grouped_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad0a739-3969-4cb5-81b9-d176bacefdf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can now use a t-test to see if the total number of cattle slaughtered is statistically different by their type of use (beef or dairy)\n",
    "# The data for each type of use is from the same time periods, so we want to use a paired t-test.\n",
    "\n",
    "t.test(grouped_weights[grouped_weights$TypeOfUse == 'Beef',]$tot_number_animals,grouped_weights[grouped_weights$TypeOfUse == 'Dairy',]$tot_number_animals,paired=TRUE)\n",
    "\n",
    "# or again using the more compact formula synatx\n",
    "t.test(tot_number_animals ~ TypeOfUse, data = grouped_weights,paired=TRUE)\n",
    "\n",
    "# We can also explore the one-sided tests, where we can change default setting from \"alternative='two.sided'\" to \"alternative='greater'\" or \"alternative='less'\".\n",
    "# Based on the data, which one-sided test would you expect to be significant?\n",
    "# How does the p-value compare for that one-sided test compared to the two-sided test?\n",
    "# Why does that depend on the symmetry of the distribution?\n",
    "\n",
    "t.test(tot_number_animals ~ TypeOfUse, data = grouped_weights,paired=TRUE,alternative='two.sided')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ce5826-e6ee-4424-bea2-c3186274f625",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The t-test we were using implicitly assumes unequal variances in the two sets of samples (var.equal=FALSE).\n",
    "# Was this the correct assumption to make?\n",
    "\n",
    "var.test(slaughter_weights[slaughter_weights$TypeOfUse == 'Beef',]$std, slaughter_weights[slaughter_weights$TypeOfUse == 'Dairy',]$std)\n",
    "\n",
    "# again with the ~ syntax\n",
    "var.test(std ~ TypeOfUse, data=slaughter_weights)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.2.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
