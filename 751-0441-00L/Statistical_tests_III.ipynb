{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "588c2112-d568-43dd-ba9a-edf1b8af825a",
   "metadata": {},
   "source": [
    "# Statistical Tests III\n",
    "---\n",
    "\n",
    "Solutions are provided below.  \n",
    "Each example contains easier parts at the start, plus more challenging extensions.  \n",
    "The extensions are useful to understand the concepts more generally, and are likely close to the difficulty of the final parts of an exam question.\n",
    "\n",
    "---\n",
    "\n",
    "#### Warmup\n",
    "\n",
    "We discussed the datasaurus dozen in the lecture, where obviously different patterns end up with incredibly similar statistical properties.  \n",
    " - Plot out some the different datasets and calculate the correlation coefficients. How does the coefficient compare to what you would estimate.\n",
    " - How do the values compare across different datasets?\n",
    "   \n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d85a61-d112-473c-8d22-90421411655d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the datasaurus package.\n",
    "library(datasauRus)\n",
    "\n",
    "# Slice out the 'dino' entries. Plot them and find the correlation coefficient.\n",
    "dino <- datasaurus_dozen[datasaurus_dozen$dataset == 'dino',]\n",
    "plot(y ~ x, data=dino, type = \"p\",col=\"darkgreen\",cex=3,lwd=4)\n",
    "result <- cor.test(dino$x,dino$y)\n",
    "\n",
    "# print out the results in a nicer way.\n",
    "cat(\"\\nCorrelation\\n-------\\nr =\",result$estimate,\"\\nr2 =\",result$estimate**2,\"\\np =\",result$p.value,\"\\n\")\n",
    "\n",
    "# Repeat for the slant_down and slant_up datasets.\n",
    "slant_down <- datasaurus_dozen[datasaurus_dozen$dataset == 'slant_down',]\n",
    "plot(y ~ x, data=slant_down, type = \"p\",col=\"darkgreen\",cex=3,lwd=4)\n",
    "result <- cor.test(slant_down$x,slant_down$y)\n",
    "cat(\"\\nCorrelation\\n-------\\nr =\",result$estimate,\"\\nr2 =\",result$estimate**2,\"\\np =\",result$p.value,\"\\n\")\n",
    "\n",
    "slant_up <- datasaurus_dozen[datasaurus_dozen$dataset == 'slant_up',]\n",
    "plot(y ~ x, data=slant_up, type = \"p\",col=\"darkgreen\",cex=3,lwd=4)\n",
    "result <- cor.test(slant_up$x,slant_up$y)\n",
    "cat(\"\\nCorrelation\\n-------\\nr =\",result$estimate,\"\\nr2 =\",result$estimate**2,\"\\np =\",result$p.value,\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f6b65f-2414-4427-b361-e47a1c35426c",
   "metadata": {},
   "source": [
    "---\n",
    "#### Example 1\n",
    "\n",
    "Consider some crop yield data from Frossard 2019, in particular the number of ears of wheat and the number of ears with grains.\n",
    " - Load in the data and plot *nr.ears.m2* against *DW.ears_with_grains.g.m2*\n",
    " - Test if the above variables are correlated.\n",
    " - Repeat the two tasks above but using *nr.ears.m2* and *soil.cover.morning*. Does the differences in correlation make sense based on your expectations for these variables.\n",
    "\n",
    "**Extension**\n",
    " - What will sorting the data (like `ears <- sort(crop_data$nr.ears.m2)`) first do to the correlation coefficients and significance?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70115bac-686c-4eb1-9e8b-398a6aab0a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the data and plot it.\n",
    "crop_data <- read.table('Frossard_2019.csv',header=TRUE,sep=\",\")\n",
    "plot(crop_data$nr.ears.m2,crop_data$DW.ears_with_grains.g.m2, type = \"p\",col=\"darkgreen\",cex=3,lwd=4)\n",
    "\n",
    "#Let's calculate the correlation coefficient and p-value.\n",
    "# By default, it is the Pearson method.\n",
    "result <- cor.test(crop_data$nr.ears.m2,crop_data$DW.ears_with_grains.g.m2)\n",
    "result\n",
    "\n",
    "# print out the results in a nicer way.\n",
    "cat(\"\\nCorrelation\\n-------\\nr =\",result$estimate,\"\\nr2 =\",result$estimate**2,\"\\np =\",result$p.value,\"\\n\")\n",
    "\n",
    "# And repeat for the *soil.cover.morning* variable\n",
    "plot(crop_data$nr.ears.m2,crop_data$soil.cover.morning, type = \"p\",col=\"pink\",cex=3,lwd=4)\n",
    "cor.test(crop_data$nr.ears.m2,crop_data$soil.cover.morning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9b303e-8686-4547-ad22-77cf617d3467",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Example 1 extension\n",
    "# What will sorting the data (like ears <- sort(crop_data$nr.ears.m2)) first do to the correlation coefficients and significance?\n",
    "\n",
    "ears <- sort(crop_data$nr.ears.m2)\n",
    "weight <- sort(crop_data$DW.ears_with_grains.g.m2)\n",
    "plot(ears, weight, type = \"p\",col=\"darkgreen\",cex=3,lwd=4)\n",
    "result <- cor.test(ears,weight)\n",
    "cat(\"Correlation of sports scores\\nr =\",result$estimate,\"\\nr2 =\",result$estimate**2,\"\\np =\",result$p.value,\"\\n\")\n",
    "\n",
    "# Sorting the data independently removes the relationship between the two variables, and so destroys the original correlation.\n",
    "# The plot now looks very correlated, as both variables were sorted separately, and indeed there is a strong and significant correlation.\n",
    "\n",
    "\n",
    "# Preprocessing data without careful thought can introduce or remove many important correlations, so be careful!\n",
    "# Instead, if we sort row by row, preserving the relationship, the plot looks the same as before.\n",
    "sorted_crop <- crop_data[order(crop_data$nr.ears.m2),]\n",
    "plot(sorted_crop$nr.ears.m2, sorted_crop$DW.ears_with_grains.g.m2, type = \"p\",col=\"darkgreen\",cex=3,lwd=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef740ce-1c2d-4d06-9ab6-c52ee6094db3",
   "metadata": {},
   "source": [
    "---\n",
    "#### Example 2\n",
    "\n",
    "Let's look now at the average annual temperature.\n",
    " - Make a scatterplot for temperature over time and calculate the pearson correlation.\n",
    " - Try calculating the spearman and kendall correlations as well, and compare the significances. How does that match the interpretation for linear versus monotonic relationships?\n",
    "\n",
    "**Extension**\n",
    " - What happens if you change the year values slightly (by less than 1.0 years), how much do the correlations change? What if you change by more than 1.0 years?\n",
    " - What happens to the correlations if you change one temperature value to be a huge outlier?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb3f7e9-c31e-4b35-aeb7-958ef2764cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The years have been relabelled for simplicitly to start from 1.\n",
    "Temperatures <- c(51.5,52.0,52.5,52.7,48.6,52.3,49.6,50.8,51.0,52.8,52.0,52.6,53.0,52.9,51.4,50.8,51.2,50.3,51.0,50.4,51.6,50.6,49.7,51.0,53.9,53.5,52.1,50.6,51.8,51.7,51.2,52.4,50.1,53.6,50.3,54.7,53.9,54.3,53.4,52.9,53.3,53.7,53.8,52.0,55.0,52.1,53.4,53.8,53.8,51.9,52.1,52.7,51.8,56.6,53.3,55.6,56.3,56.2,56.1,56.2,53.6,55.7,56.3)\n",
    "Years <- c(1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63)\n",
    "\n",
    "# Plot the data and calculate the pearson (default) correlation.\n",
    "plot(Years, Temperatures, type = \"p\",col=\"darkred\",cex=3,lwd=4)\n",
    "result <- cor.test(Years,Temperatures)\n",
    "cat(\"\\nCorrelation of annual temperatures\\nr =\",result$estimate,\"\\nr2 =\",result$estimate**2,\"\\np =\",result$p.value,\"\\n\")\n",
    "\n",
    "# Let's also look the Spearman and Kendall correlations.\n",
    "# We have \"ties\" in our data, where the temperatures are the same across two years.\n",
    "# We use an approximation to handle these ties rather than the exact method.\n",
    "result <- cor.test(Years,Temperatures,method='spearman',exact=F)\n",
    "cat(\"\\nCorrelation of annual temperatures (Spearman)\\nr =\",result$estimate,\"\\nr2 =\",result$estimate**2,\"\\np =\",result$p.value,\"\\n\")\n",
    "result <- cor.test(Years,Temperatures,method='kendall',exact=F)\n",
    "cat(\"\\nCorrelation of annual temperatures (Kendall)\\nr =\",result$estimate,\"\\nr2 =\",result$estimate**2,\"\\np =\",result$p.value,\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226f1673-e6ab-4c22-a0c2-1ba002ba9567",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Example 2 extension\n",
    "# What happens if you change year values slightly, how much do the correlations change?\n",
    "\n",
    "# We can add normally distributed random noise (mean=0 and sd=0.05) to Years as Years+rnorm(length(Years),0,.05)\n",
    "Years <- Years+rnorm(length(Years),0,2)\n",
    "plot(Years, Temperatures, type = \"p\",col=\"darkred\",cex=3,lwd=4)\n",
    "\n",
    "# We can recalculate the correlation.\n",
    "result <- cor.test(Years,Temperatures,method=\"pearson\",exact=F)\n",
    "cat(\"\\nCorrelation of annual temperatures\\nr =\",result$estimate,\"\\nr2 =\",result$estimate**2,\"\\np =\",result$p.value,\"\\n\")\n",
    "\n",
    "# There is a slight but insignificant change to the correlation and p value when using pearson R.\n",
    "# Since the years don't change enough to swap ranks, the spearman R is totally unchanged.\n",
    "# Increasing the variance to say 2 will affect both correlations.\n",
    "\n",
    "# What happens to the correlations if you change one value to be a huge outlier?\n",
    "Temperatures[15] = 80.7\n",
    "\n",
    "result_p <- cor.test(Years,Temperatures,method=\"pearson\",exact=F)\n",
    "cat(\"\\nCorrelation of annual temperatures\\nr =\",result_p$estimate,\"\\nr2 =\",result_p$estimate**2,\"\\np =\",result_p$p.value,\"\\n\")\n",
    "\n",
    "result_s <- cor.test(Years,Temperatures,method=\"spearman\",exact=F)\n",
    "cat(\"\\nCorrelation of annual temperatures\\nr =\",result_s$estimate,\"\\nr2 =\",result_s$estimate**2,\"\\np =\",result_s$p.value,\"\\n\")\n",
    "\n",
    "# Pearson correlation can be totally changed (depending on how big the outlier is), but there will be almost no effect to spearman, as the coordinate doesn't matter, only the ranks."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5e92ada3-7a43-4394-8989-ed46910342e2",
   "metadata": {},
   "source": [
    "---\n",
    "#### Example 3\n",
    "\n",
    "Let's investigate the \"spurious correlation of ratios\" effect.\n",
    " - Generate three sets of normally distributed data, which can have the same mean and std.\n",
    " - Make a scatterplot using two of the datasets as X/Y and the third dataset as the colour of each point.\n",
    " - Test the correlation of X and Y, and then check the correlation of X/Z and Y/Z.\n",
    "\n",
    "\n",
    "Let's consider (randomly generated) dairy yield from two different cattle breeds.\n",
    " - Generate two sets of normally distributed data, use the same sample size and std, but a different mean.\n",
    " - Plot the distributions using histograms.\n",
    " - Use an appropriate statistical test to see if the two cattle breeds have similar milk yields.\n",
    "\n",
    "**Extension**\n",
    " - What happens if you change the standard deviation for X/Y/Z? Does the correlation match the equation from the slides?\n",
    " - What could we change to make the results match the expectations better?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50711f6d-1c94-4e87-8236-c4bfd0853263",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consider 3 random variables that are normally distributed (with identical parameters).\n",
    "N_samples = 50\n",
    "\n",
    "X <- rnorm(N_samples,100,5)\n",
    "Y <- rnorm(N_samples,100,5)\n",
    "Z <- rnorm(N_samples,100,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf0fd1e-a9d5-4cec-9aed-da5784d8e56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a colour palette (\"viridis\"-like) that goes from blue->yellow.\n",
    "YlOrBrRdBu <- c(\"#FDE725\", \"#21908C\", \"#3B528B\", \"#440154\")\n",
    "col <- colorRampPalette(YlOrBrRdBu)(50)\n",
    "\n",
    "# Roughly bin the Z values so we can colour each scatter point by the Z value, and then plot.\n",
    "cols = col[cut(Z,50)]\n",
    "plot(X, Y, col=cols,type = \"p\",cex=3,lwd=2)\n",
    "\n",
    "# Let's calculate the correlation as well.\n",
    "result <- cor.test(X,Y)\n",
    "cat(\"Correlation of X and Y\\nr =\",result$estimate,\"\\nr2 =\",result$estimate**2,\"\\np =\",result$p.value,\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42a896a-e150-481e-9e20-445a5bc250a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's divide X & Y by Z.\n",
    "# This may be some normalisation procedure or similar approach.\n",
    "# We are using the same colours as determined in the previous panel.\n",
    "plot(X/Z, Y/Z, col=cols,type = \"p\",cex=3,lwd=2)\n",
    "result <- cor.test(X/Z,Y/Z)\n",
    "cat(\"Correlation of X and Y\\nr =\",result$estimate,\"\\nr2 =\",result$estimate**2,\"\\np =\",result$p.value,\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1efec728-97fc-474d-9c7f-907792265004",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Example 3 extension\n",
    "# What happens if you alter the standard deviation for X/Y/Z?\n",
    "\n",
    "# If the standard deviation is huge the result is less significant, while a lower deviation is more reliably significant.\n",
    "# Huge outliers with high deviation can skew the data much more, so this is expected.\n",
    "\n",
    "# Does it match the equation expectations from the slides?\n",
    "\n",
    "X <- rnorm(200,50,10)\n",
    "Y <- rnorm(200,50,10)\n",
    "Z <- rnorm(200,50,10)\n",
    "result <- cor.test(X/Z,Y/Z)\n",
    "cat(\"Correlation of X and Y\\nr =\",result$estimate,\"\\nr2 =\",result$estimate**2,\"\\np =\",result$p.value,\"\\n\")\n",
    "\n",
    "X <- rnorm(200,50,5)\n",
    "Y <- rnorm(200,50,5)\n",
    "Z <- rnorm(200,50,20)\n",
    "result <- cor.test(X/Z,Y/Z)\n",
    "cat(\"Correlation of X and Y\\nr =\",result$estimate,\"\\nr2 =\",result$estimate**2,\"\\np =\",result$p.value,\"\\n\")\n",
    "\n",
    "# Yes, we can calculate this.\n",
    "# In the first case, the equation predicts r=0.5, and in the second it is about 0.941\n",
    "\n",
    "\n",
    "# What could we do to make the results match expectations better?\n",
    "\n",
    "X <- rnorm(200,10000,5)\n",
    "Y <- rnorm(200,10000,5)\n",
    "Z <- rnorm(200,10000,20)\n",
    "result <- cor.test(X/Z,Y/Z)\n",
    "cat(\"Correlation of X and Y\\nr =\",result$estimate,\"\\nr2 =\",result$estimate**2,\"\\np =\",result$p.value,\"\\n\")\n",
    "\n",
    "# The equation shown in the lectures is a slight approximation, as there is also a dependence on the mean in the full expression.\n",
    "# If we increase the mean, we can get r values much closer to 0.941."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7073567b-6c1b-49c6-9754-be3a21cc51c5",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "#### Example 4\n",
    "\n",
    "We can also examine correlations across many sets of data at once, rather than between just a pair of observations.\n",
    " - Create a 10x10 matrix of randomly distributed variates.\n",
    " - Calculate the correlation coefficient and signifiance across all the pairwise combinations.\n",
    " - Plot the results using the `corrplot` package.\n",
    "\n",
    "**Extension**\n",
    " - Verify that the correlation matrix values match calculating the correlations between some pairs of columns.\n",
    " - If we change the distribution from exponential to normal, how many correlations are \"falsely\" significant?\n",
    " - If we change the correlation to spearman (from pearson), would we expect to see more significant correlations with the exponential distribution?\n",
    " - Consider how many of these \"random\" sets of data are correlated. We will investigate this \"multiple hypothesis testing\" problem in detail next lecture.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4238d9df-2e52-4c7d-806d-eae6cfdebc8b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Install the corrplot package if necessary.\n",
    "install.packages(\"corrplot\")\n",
    "\n",
    "# Load the corrplot package.\n",
    "library(corrplot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d674b3-3e15-4ada-b4eb-8de75390e49f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Make a matrix with random expoential values, calculate the (pairwise) correlation matrix.\n",
    "A <- matrix(rexp(100,5),nrow=10)\n",
    "\n",
    "# Add some names to the columns to make it look a bit nicer.\n",
    "colnames(A) <- c(\"Alpha\",\"Bravo\",\"Charlie\",\"Delta\",\"Echo\",\"Foxtrot\",\"Golf\",\"Hotel\",\"India\",\"Juliett\")\n",
    "\n",
    "# Test for correlations across the matrix.\n",
    "correlations <- cor(A,method=\"pearson\")\n",
    "\n",
    "# Also calculate the p-values for the correlations.\n",
    "p = cor.mtest(A)$p\n",
    "\n",
    "# Plot the correlation matrix, indicate which correlations are not significant.\n",
    "corrplot(correlations,type = \"upper\",p.mat=p,sig.level=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87a3d99-ef14-4038-b54f-b89477baef76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Example 4 extension\n",
    "# What happens if you alter the standard deviation for X/Y/Z?\n",
    "\n",
    "# Verify that the correlation matrix values match calculating the correlations between each column.\n",
    "# We can access each column like A[,\"Alpha\"] or A[,\"Golf\"], and each element of the correlation matrix like correlations[\"Alpha\",\"Golf\"].\n",
    "cat(\"Direct test\\nr = \",cor.test(A[,\"Alpha\"],A[,\"Golf\"])$estimate,\"\\nMatrix correlation\\nr =\",correlations[\"Alpha\",\"Golf\"])\n",
    "\n",
    "# If we change the distribution from exponential to normal, how many correlations are \"falsely\" significant?\n",
    "A <- matrix(rnorm(100,50,2),nrow=10)\n",
    "colnames(A) <- c(\"Alpha\",\"Bravo\",\"Charlie\",\"Delta\",\"Echo\",\"Foxtrot\",\"Golf\",\"Hotel\",\"India\",\"Juliett\")\n",
    "correlations <- cor(A,method=\"pearson\")\n",
    "p = cor.mtest(A)$p\n",
    "corrplot(correlations,type = \"upper\",p.mat=p,sig.level=0.05)\n",
    "\n",
    "\n",
    "# If we change the correlation to spearman (from pearson), would we expect to see more significant correlations with the exponential distribution?\n",
    "A <- matrix(rexp(100),nrow=10)\n",
    "colnames(A) <- c(\"Alpha\",\"Bravo\",\"Charlie\",\"Delta\",\"Echo\",\"Foxtrot\",\"Golf\",\"Hotel\",\"India\",\"Juliett\")\n",
    "correlations <- cor(A,method=\"spearman\")\n",
    "p = cor.mtest(A)$p\n",
    "corrplot(correlations,type = \"upper\",p.mat=p,sig.level=0.05)\n",
    "\n",
    "# An exponential distribution generally has more extreme values (outliers) than a normal distribution, which could either lead to a larger or smaller correlation.\n",
    "# Since spearman is more robust to outliers (and we don't expect any signficance from a random set of values), we would expect it to have fewer significant correlations compared to pearson."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703bc34e-278e-4bd1-bdd8-62a69415931e",
   "metadata": {},
   "source": [
    "---\n",
    "## Real world example\n",
    "\n",
    "This is a slightly more realistic case, where we are examining some [actual data](https://opendata.swiss/en/dataset/rinder-verteilung-pro-gemeinde).  \n",
    "The goal here is to manipulate the data into a useful shape, and then assess statistical significance.  \n",
    "These examples are harder than you would encounter in an exam and use more advanced data analysis techniques, but are useful to try.\n",
    "\n",
    "This data is the number of cattle for each commune in Switzerland\n",
    " - Filter out communes that have values of 0 for the count of cattle, as these are likely incomplete records.\n",
    " - Plot the count of cattle against the countPerSurfacekm2 (and also against countPer100Inhabitants).\n",
    " - Test for correlation betweeen these variables\n",
    "   -  See if you can make an interpretation about which types communes (in terms of land area or population density) have large amounts of cattle\n",
    " - How does changing the filtering in the first step (filtering out communes with less than 100/500/1000/etc cattle) change these results?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dec1223-17b5-4a67-9130-8efeaf13f2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the data from the csv, which uses ';' as the separator rather than ','.\n",
    "# The first row of the file is also some download information rather than data, so we skip the first row.\n",
    "cattle_by_communes <- read.csv('cattle-map-commune.csv',sep=';',skip=1)\n",
    "\n",
    "# Filter out communes that have less than N cattle.\n",
    "# Try changing the value of N and seeing how the correlation analyses change.\n",
    "# What does that imply about the data?\n",
    "\n",
    "N=1\n",
    "cattle_by_communes <- cattle_by_communes[(cattle_by_communes$count >= N),] \n",
    "\n",
    "# Plot the data.\n",
    "plot(countPerSurfacekm2 ~ count,data=cattle_by_communes)\n",
    "\n",
    "# And test for correlation.\n",
    "cor.test(cattle_by_communes$count,cattle_by_communes$countPerSurfacekm2,method=\"spearman\",exact=FALSE)\n",
    "cor.test(cattle_by_communes$count,cattle_by_communes$countPer100Inhabitants,method=\"spearman\",exact=FALSE)\n",
    "\n",
    "# We can use the ~ syntax as well.\n",
    "cor.test(~ countPer100Inhabitants + count, data=cattle_by_communes,method=\"spearman\",exact=FALSE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.2.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
