{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b7555a-45ee-4a4e-83bf-bd68dbbda929",
   "metadata": {},
   "outputs": [],
   "source": [
    "## EXAMPLE 3 -- Multiple hypothesis testing\n",
    "# Consider flipping a coin. There are two outcomes (heads or tails), and so this is called a \"Bernoulli trial\" (or binomial trial).\n",
    "# Let's flip the coin 5 times, using the binomial distribution with a probability of 0.5.\n",
    "# Assume landing on heads is \"1\" and landing on tails is \"0\".\n",
    "\n",
    "Flips <- rbinom(5,1,.5)\n",
    "cat(\"Flips:\",Flips,\"\\nNumber of heads:\",sum(Flips),\"\\n\\n\")\n",
    "\n",
    "\n",
    "# Now let's simulate this for many people.\n",
    "# Flip 6000 coins, and split into 10000 people (so same as each flipping 10 times).\n",
    "\n",
    "Flips <- matrix(rbinom(10000,1,.5),nrow = 1000)\n",
    "\n",
    "# Sum over each row, so counting how many heads each person flipped.\n",
    "# Print the mean number of heads each person flipped, and a histogram.\n",
    "\n",
    "Sums <- rowSums(Flips)\n",
    "MeanHeads <- mean(Sums)\n",
    "cat(\"Mean number of heads flipped:\",MeanHeads,\"\\n\")\n",
    "hist(Sums,breaks = seq(-1,11,length.out = 12))\n",
    "\n",
    "# How does it look per person?\n",
    "# Would someone say the coin if unfair if they rolled 2 heads? 9 heads?\n",
    "\n",
    "cat(\"Rolling 2 heads: p =\",binom.test(2,10,.5)$p.value,\"\\nRolling 9 heads: p =\",binom.test(9,10,.5)$p.value,\"\\n\")\n",
    "\n",
    "# We have to correct for the number of people \"testing\" the coin, in this case 100000 people.\n",
    "# So the critical p-value isn't 0.05 anymore, but 0.05/100000 = 5e-7.\n",
    "\n",
    "# Let's push it a bit further, consider N flips and B people (so N/B flips per person)\n",
    "\n",
    "N = 10000\n",
    "B = 500\n",
    "cat(\"Number of flips per person: \",N/B,\"\\n\")\n",
    "\n",
    "# Change the seed used to generate random numbers, so we can *reproducibly* generate random datasets.\n",
    "# It is a complicated topic, but don't fall into the trap that similar seeds produce similar results.\n",
    "# Try commenting one value out and swapping the other in and see what happens.\n",
    "\n",
    "set.seed(6)\n",
    "#set.seed(5)\n",
    "\n",
    "# Generate per-person p values for a binomial test.\n",
    "# `sapply` applies the function given in the second argument to each element of data in the first argument.\n",
    "# This gives us the raw p values that each person calculated for their set of N/B flips.\n",
    "\n",
    "RawP <- sapply(sort(rowSums(matrix(rbinom(N,1,.5),nrow = B))), function(x) binom.test(x, N/B, .5)$p.value)\n",
    "cat(\"Number of \\\"significant\\\" tests without correction:\",sum(RawP<0.05),\"\\n\")               \n",
    "\n",
    "# Now we can correct the p values using two different methods.\n",
    "# Note that this adjusts the p values upwards, which is essentially equal to but more obvious than adjusting the significance threshold downwards.\n",
    "\n",
    "BP <- p.adjust(RawP,\"bonferroni\")\n",
    "BHP <- p.adjust(RawP,\"BH\")\n",
    "cat(\"Number of \\\"significant\\\" tests with Bonferroni correction:\",sum(BP<0.05),\"\\n\")       \n",
    "cat(\"Number of \\\"significant\\\" tests with Benjamini-Hochberg correction:\",sum(BHP<0.05),\"\\n\")       \n",
    "               \n",
    "# Plot the raw p values on the x-axis, and the two methods of correction on the y-axis.\n",
    "# The significance threshold is still p < 0.05, marked by the line.\n",
    "\n",
    "plot(RawP,BP,col=rgb(0,0,1),ylim=c(0,1),xlab=\"Raw p\",ylab=\"Adjusted p\")\n",
    "par(new = TRUE)\n",
    "plot(RawP,BHP,col=rgb(1,0,0),ylim=c(0,1),xlab=\"\",ylab=\"\")\n",
    "abline(0.05,0)\n",
    "legend(\"right\",c(\"Bonferroni\",\"Benjamini-Hochberg\"),fill=c(rgb(0,0,1),rgb(1,0,0)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906e10b2-ade9-4da1-8c59-3247088338a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## EXAMPLE 1\n",
    "# Load in data used in the previous lecture\n",
    "\n",
    "crop_data <- read.table('Frossard_2019.csv',header=TRUE,sep=\",\")\n",
    "head(crop_data)\n",
    "\n",
    "# Let's look at the variance for two of the variables.\n",
    "\n",
    "var(crop_data$DW.grain.kg.ha)\n",
    "var(crop_data$SPAD.afternoon)\n",
    "\n",
    "# Ignoring any assumptions, we can use an F-test to see if they have equal variances.\n",
    "\n",
    "var.test(crop_data$DW.grain.kg.ha,crop_data$SPAD.afternoon)\n",
    "\n",
    "# Slightly more advanced, but we can compare the variances between two groups (the two varieties) for specific variables.\n",
    "# Here, let's look at the \"DW.grain.kg.ha\" quantity, and see if there is a difference in variance for the two varieties.\n",
    "# We can do that manually by separating out the data and testing (using the more robust Bartlett test), or a more advanced notation using \"~\".\n",
    "\n",
    "bockris <- crop_data[crop_data$variety == \"Bockris\",]\n",
    "titlis <- crop_data[crop_data$variety == \"Titlis\",]\n",
    "bartlett.test(list(bockris$DW.grain.kg.ha,titlis$DW.grain.kg.ha))\n",
    "\n",
    "# And this should be equal (but easier to write!)\n",
    "\n",
    "bartlett.test(DW.grain.kg.ha ~ variety, data = crop_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73714f55-6d01-4b1d-af4d-843bb3e06ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXAMPLE 2\n",
    "\n",
    "# Load a default dataset for the weight of plants after 3 different types of treatments.\n",
    "# Plot the weights as boxplots to visualise potential group differences.\n",
    "\n",
    "boxplot(weight ~ group, data = PlantGrowth, frame = FALSE,\n",
    "        col = c(\"#999999\", \"#E69F00\", \"#56B4E9\"))\n",
    "\n",
    "# We want to test if there is any significant differences between the three groups.\n",
    "# We will use the Kruskal-Wallis test.\n",
    "\n",
    "kruskal.test(PlantGrowth$weight, PlantGrowth$group)\n",
    "\n",
    "\n",
    "# However, this just shows that there is a significant difference, but it is not clear between which groups.\n",
    "# We can do pairwise tests (e.g. \"ctrl\" and \"trt1\", \"ctrl\" and \"trt2\", etc.) to see which are significant.\n",
    "# Be careful, as we are now testing multiple hypotheses and so should correct accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e0eb8e-5d1c-428e-b70d-ffe332ed662a",
   "metadata": {},
   "outputs": [],
   "source": [
    "PlantGrowth\n",
    "pairwise.wilcox.test(PlantGrowth$weight, PlantGrowth$group,   p.adjust.method = \"BH\",exact=F)\n",
    "pairwise.wilcox.test(PlantGrowth$weight, PlantGrowth$group,   p.adjust.method = \"none\",exact=F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f871f6-c81f-4571-ac84-2efcd7c096f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## EXAMPLE 3\n",
    "\n",
    "# We can also look at a different dataset.\n",
    "# Use the \"iris\" default dataset for flowers.\n",
    "\n",
    "head(iris)\n",
    "\n",
    "# Here we will plot the sepal width for the three different species\n",
    "\n",
    "boxplot(Sepal.Width ~ Species, data = iris, frame = FALSE,\n",
    "        col = c(\"#999999\", \"#E69F00\", \"#56B4E9\"))\n",
    "\n",
    "# However, there are other variables, so we can try and plot this as an \"all-versus-all\" pair plot.\n",
    "# First we should convert the numeric data to a matrix, and also turn the species names into numeric values to make plotting easier.\n",
    "\n",
    "ma <- as.matrix(iris[, 1:4])\n",
    "speciesID <- as.numeric(iris$Species)\n",
    "pairs(ma, col = rainbow(3)[speciesID])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d906bf-1557-4f15-aade-af36b7091d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's test the significance of sepal length for the different species.\n",
    "kruskal.test(iris$Sepal.Length, iris$Species)\n",
    "\n",
    "# And again do a pairwise test to see which groups are significant.\n",
    "\n",
    "pairwise.wilcox.test(iris$Sepal.Length, iris$Species,   p.adjust.method = \"BH\",exact=F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3585245d-dae0-40f9-9b55-221f58dc1b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install a package called matrixTests we will use for simplicity.\n",
    "#install.packages(\"matrixTests\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e963234-906d-49b2-88f6-1329723a3109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the package and then do a column-wise test for all the variables\n",
    "\n",
    "library(\"matrixTests\")\n",
    "col_kruskalwallis(ma, speciesID)\n",
    "\n",
    "# Compare to doing each test manually, and confirm identical results.\n",
    "\n",
    "kruskal.test(iris$Sepal.Length, iris$Species)\n",
    "kruskal.test(iris$Sepal.Width, iris$Species)\n",
    "kruskal.test(iris$Petal.Length, iris$Species)\n",
    "kruskal.test(iris$Petal.Width, iris$Species)\n",
    "\n",
    "# Note the p-values that are too small get reported as < 2.2e-16, because the computer loses accuracy for numbers smaller than this.\n",
    "# To get the exact number back, we can do\n",
    "\n",
    "kruskal.test(iris$Petal.Width, iris$Species)$p.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f957d0a4-93c6-4cbb-9136-78b2f6752e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I couldn't find a simple approach to do multiple multiple hypothesis testing, so we can do this manually.\n",
    "\n",
    "pairwise.wilcox.test(iris$Sepal.Length, iris$Species,   p.adjust.method = \"BH\",exact=F)\n",
    "pairwise.wilcox.test(iris$Sepal.Width, iris$Species,   p.adjust.method = \"BH\",exact=F)\n",
    "pairwise.wilcox.test(iris$Petal.Length, iris$Species,   p.adjust.method = \"BH\",exact=F)\n",
    "pairwise.wilcox.test(iris$Petal.Width, iris$Species,   p.adjust.method = \"BH\",exact=F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7fad6b-0e89-4a87-9558-3d9f46631eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "## EXAMPLE 4\n",
    "\n",
    "# Test if the data is normally distributed (a requirement for anova)\n",
    "\n",
    "shapiro.test(crop_data$TKG.g)\n",
    "shapiro.test(crop_data$nr.ears.m2)\n",
    "\n",
    "# Perform a regression analysis and assess the p-value\n",
    "\n",
    "summary(lm(TKG.g ~ nr.ears.m2, data = crop_data))\n",
    "\n",
    "# Jumping ahead a bit, but this is the analysis of variance (ANOVA) approach, which is a type of parametric f-test.\n",
    "\n",
    "summary(aov(TKG.g ~ nr.ears.m2, data = crop_data))\n",
    "\n",
    "# Since one of the variables was not normally distributed, we failed the required assumptions.\n",
    "# Kruskal-Wallis is again the more appropriate test to use, and notice the diffence in p-value.\n",
    "\n",
    "kruskal.test(TKG.g ~ nr.ears.m2, data = crop_data)\n",
    "\n",
    "# The order-response variables **matters** a lot.\n",
    "# If you swap the order, it is no longer the same analysis (as it was in correlation and many other statistical tests).\n",
    "\n",
    "kruskal.test(nr.ears.m2 ~ TKG.g, data = crop_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db12ae23-6e4f-4956-a10b-ae5f1f08bb75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consider another set of variables, are they normal?\n",
    "\n",
    "shapiro.test(crop_data$DW.grain.kg.ha)\n",
    "shapiro.test(crop_data$SPAD.afternoon)\n",
    "\n",
    "# Go ahead and calculate and plot the regression so we can visualise the relationship.\n",
    "regression <- lm(DW.grain.kg.ha ~ SPAD.afternoon, data=crop_data)\n",
    "summary(regression)\n",
    "plot(DW.grain.kg.ha ~ SPAD.afternoon, data = crop_data)\n",
    "abline(regression,col=\"red\",lw=4)\n",
    "\n",
    "# The data does approximately satisfy the requirements for an F-test, so the nonparametric version is less powerful.\n",
    "\n",
    "kruskal.test(DW.grain.kg.ha ~ SPAD.afternoon, data = crop_data)\n",
    "\n",
    "\n",
    "# Given a F statistic, how many samples would we need (assuming they follow the same pattern as the existing data) to be significant?\n",
    "\n",
    "my.F <- 3.883\n",
    "my.n <- 18:1000\n",
    "my.p <- pf(my.F, 1, my.n-2, lower.tail=F)\n",
    "plot(my.p, my.n, type=\"l\")\n",
    "abline(v=0.05, col=\"red\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4461ad-85ce-4a02-be51-a0d88d3f828f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's look at a more advanced example again\n",
    "\n",
    "# Read in the semi-colon separated data, skipping the first line which is a comment.\n",
    "births <- read.csv('cattle-birthCanton.csv',sep=';',skip=1)\n",
    "\n",
    "# We want to sum over *all* columns by aggregating over year, so we can use the ~ syntax over \".\" (all coloumns). \n",
    "grouped_births <- aggregate(. ~ Year,data=births, FUN=sum)\n",
    "grouped_births\n",
    "\n",
    "\n",
    "# We'll look at a subset of four cantons and plot the number of births of the different years\n",
    "melted_births_subset1 <- melted_births[melted_births$Canton %in% c('AG','VD','BE','VS'),]\n",
    "plot(Births ~ Year, data = melted_births_subset1,col=factor(melted_births_subset1$Canton),frame = FALSE)\n",
    "\n",
    "# and we can test for correlations between the cantons, here are two examples.\n",
    "cor.test( grouped_births$AG, grouped_births$VD)\n",
    "cor.test( grouped_births$BE, grouped_births$VS)\n",
    "\n",
    "\n",
    "# We want to test if there is any significant differences between the three groups.\n",
    "# We will use the Kruskal-Wallis test.\n",
    "\n",
    "# We'll take another subset of cantons, and reshape the dataframe (\"melt\" it) so the cantons change from being columns to being row values\n",
    "melted_births <- reshape2::melt(grouped_births, id.vars = c(\"Year\", \"Month\"),variable.name = \"Canton\", value.name = \"Births\")\n",
    "melted_births_subset2 <- melted_births[melted_births$Canton %in% c('GR','TG','ZH','SZ','SO','UR','TI'),]\n",
    "\n",
    "# We need to convert the column type from \"fct\" (function) to \"str\" (string), which will remove all the cantons we don't care about above.\n",
    "# You should try redoing the boxplot after commenting out these two lines and seeing what changes.\n",
    "i <- sapply(melted_births_subset2, is.factor)\n",
    "melted_births_subset2[i] <- lapply(melted_births_subset2[i], as.character)\n",
    "\n",
    "\n",
    "boxplot(Births ~ Canton, data = melted_births_subset2, frame = FALSE)\n",
    "\n",
    "# We will use the Kruskal-Wallis test to test if there is any significant differences between the cantons.\n",
    "kruskal.test(Births ~ Canton, data = melted_births_subset2)\n",
    "\n",
    "\n",
    "# However, this just shows that there is *a* significant difference, but it is not clear between which groups.\n",
    "# We can do pairwise tests (e.g. SZ and ZH, SZ and SO, etc.) to see which are significant.\n",
    "# Be careful, as we are now testing multiple hypotheses and so we need to correct accordingly.\n",
    "\n",
    "pairwise.t.test(melted_births_subset2$Births, melted_births_subset2$Canton, p.adjust.method = \"bonf\",paired=TRUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c20cd27-21cb-4a4f-aa62-f6af6fcd67c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.2.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
